ridge_fit2=glmnet(bre_train[,1:9],bre_train[,10],alpha=0,standardize=FALSE,lambda=lambda_min,family="binomial")
#使用预测函数对测试集数据进行预测
phat_test_ridge = predict(ridge_fit2, as.matrix(bre_test[,1:9]), s=lambda_min, type = "response")
yhat_test_ridge = ifelse(phat_test_ridge>0.5,1,0)
#Compute test error
(test_error_ridge = 1- mean((bre_test$Class==yhat_test_ridge)))
#测试集误差为2.18%
(confusion_test1 = table("observed"=bre_test$Class, "predicted"=yhat_test_ridge))
#The LASSO
#使用LASSO重新检查乳腺癌训练数据
#choose grid of values for the tuning parameter
grid=10^seq(5,-3,length=100)
#fit a LASSO regression for each value of the tuning parameter
lasso_fit=glmnet(bre_train[,1:9],y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family = "binomial")
#提取LASSO系数
beta_hat2=coef(lasso_fit)
#作图
plot(lasso_fit,xvar="lambda",col=1:9,label=TRUE)
#从图中可以看出，随着调优参数值的增加，第五个变量(浅蓝色)Epith.c.size是第一个退出模型的变量,接着是第九个Mitoses，接着是第6个(黄色)Bare.nuclei，第7个变量(紫色)Bl.cromatin
#为调优参数选择一个合适的值，同样利用10倍交叉验证
#fit model,applying 10-fold cross validation
lasso_cv_fit=cv.glmnet(as.matrix(bre_train[,1:9]),y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family="binomial",type.measure="class")
##plot the cross-validation
plot(lasso_cv_fit)
#extract the optimal value of the tuning parameter
(lambda_min2=lasso_cv_fit$lambda.min)
#调优参数最小的参数
(i2=which(lasso_cv_fit$lambda==lasso_cv_fit$lambda.min))
#extract corresponding mean MSE
lasso_cv_fit$cvm[i2]
#得到的平均MSE=0.03296
#通过LASSO计算回归系数
coef(lasso_fit,s=lambda_min2)
##判别分析##
##不剔除任何变量
library(nclSLR)
linDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the LDA calssifier using the training data
lda_train1=lda(Class~.,data=bre_train)
##判别分析##
##不剔除任何变量
library(nclSLR)
library(MASS)
linDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the LDA calssifier using the training data
lda_train1=lda(Class~.,data=bre_train)
summary(lda_train1)
#compute fitted the values for the validation data
lda_test1=predict(lda_train1,bre_test)
yhat_test1=lda_test1$class
#calculate test confusion matirx
(confusion_test3=table(Observed=bre_test$Class,Predicted=yhat_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_test1)#3.65%
#用显著性强的5个变量做QDA
lda_train3=lda(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
lda_test3=predict(lda_train3,bre_test)
yhat_test3=lda_test3$class
#calculate test confusion matirx
(confusion_test8=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#4.38%
#剔除两个变量
##fit the LDA calssifier using the training data
lda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(lda_train2)
#compute fitted the values for the validation data
lda_test2=predict(lda_train2,bre_test)
yhat_test2=lda_test2$class
#calculate test confusion matirx
(confusion_test4=table(Observed=bre_test$Class,Predicted=yhat_test2))
#calculate the test error
1-mean(bre_test$Class==yhat_test2)#3.65%
##QDA,LASSO剔除2个变量
##fit the LDA calssifier using the training data
qda_train=qda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(qda_train)
#compute fitted the values for the validation data
qda_test=predict(qda_train,bre_test)
yhat_test3=qda_test$class
#calculate test confusion matirx
(confusion_test5=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在35+0=35次中正确预测了35次乳腺癌为恶性的概率,在97+5=102次预测乳腺癌为良性中，有97次预测正确
#calculate the test error
1-mean(bre_test2$Class==yhat_test3)#3.65%
##从混淆矩阵中可以看出在35+0=35次中正确预测了35次乳腺癌为恶性的概率,在97+5=102次预测乳腺癌为良性中，有97次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#3.65%
##不剔除任何变量
quaDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the QDA calssifier using the training data
qda_train1=lda(Class~.,data=bre_train)
#compute fitted the values for the validation data
qda_test1=predict(qda_train1,bre_test)
yhat_qua_test1=qda_test1$class
#calculate test confusion matirx
(confusion_test6=table(Observed=bre_test$Class,Predicted=yhat_qua_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test1)#3.65%
#用显著性强的6个变量做QDA
qda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
qda_test2=predict(qda_train2,bre_test)
yhat_qua_test2=qda_test2$class
#calculate test confusion matirx
(confusion_test7=table(Observed=bre_test$Class,Predicted=yhat_qua_test2))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test2)#3.65%
##LDA CV
#交叉变量(cv)
#设置随机数
set.seed(1)
##判别分析##
##不剔除任何变量
library(nclSLR)
library(MASS)
linDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the LDA calssifier using the training data
lda_train1=lda(Class~.,data=bre_train)
summary(lda_train1)
#compute fitted the values for the validation data
lda_test1=predict(lda_train1,bre_test)
yhat_test1=lda_test1$class
#calculate test confusion matirx
(confusion_test3=table(Observed=bre_test$Class,Predicted=yhat_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_test1)#3.65%
#用显著性强的6个变量做QDA
lda_train3=lda(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
lda_test3=predict(lda_train3,bre_test)
yhat_test3=lda_test3$class
#calculate test confusion matirx
(confusion_test8=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#4.38%
#剔除两个变量
##fit the LDA calssifier using the training data
lda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(lda_train2)
#compute fitted the values for the validation data
lda_test2=predict(lda_train2,bre_test)
yhat_test2=lda_test2$class
#calculate test confusion matirx
(confusion_test4=table(Observed=bre_test$Class,Predicted=yhat_test2))
#calculate the test error
1-mean(bre_test$Class==yhat_test2)#3.65%
##QDA,LASSO剔除2个变量
##fit the LDA calssifier using the training data
qda_train=qda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(qda_train)
#compute fitted the values for the validation data
qda_test=predict(qda_train,bre_test)
yhat_test3=qda_test$class
#calculate test confusion matirx
(confusion_test5=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在35+0=35次中正确预测了35次乳腺癌为恶性的概率,在97+5=102次预测乳腺癌为良性中，有97次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#3.65%
##不剔除任何变量
quaDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the QDA calssifier using the training data
qda_train1=lda(Class~.,data=bre_train)
#compute fitted the values for the validation data
qda_test1=predict(qda_train1,bre_test)
yhat_qua_test1=qda_test1$class
#calculate test confusion matirx
(confusion_test6=table(Observed=bre_test$Class,Predicted=yhat_qua_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test1)#3.65%
#用显著性强的6个变量做QDA
qda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
qda_test2=predict(qda_train2,bre_test)
yhat_qua_test2=qda_test2$class
#calculate test confusion matirx
(confusion_test7=table(Observed=bre_test$Class,Predicted=yhat_qua_test2))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test2)#3.65%
###回归正则化
##利用全部训练集做岭回归
library(glmnet)
#choose grid values for the tuning parameter
grid=10^seq(5,-3,length=100)
##fit a ridge regression model for each value of the tuning parameter
ridge_fit=glmnet(bre_train[,1:9],y1_bre_train,alpha=0,standardize=FALSE,lambda=grid,family = "binomial")
beta1_hat=coef(ridge_fit)
dim(beta1_hat)
par(mfrow=c(1,2))
plot(ridge_fit,xvar="lambda",col=1:9,label=TRUE)
#标签1到9表示对应的系数，可以看出，当时间对数约为5时，所有的回归系数本质上等于零
#因此需要为调优参数选择一个合适的值，这可以通过交叉验证来实现
ridge_cv_fit=cv.glmnet(as.matrix(bre_train[,1:9]),y1_bre_train,alpha=0,standardize=FALSE,lambda=grid,family = "binomial",type.measure = "class")
#display how the cross-validated error varies
plot(ridge_cv_fit)
#The LASSO
#使用LASSO重新检查乳腺癌训练数据
#choose grid of values for the tuning parameter
grid=10^seq(5,-3,length=100)
#fit a LASSO regression for each value of the tuning parameter
lasso_fit=glmnet(bre_train[,1:9],y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family = "binomial")
#提取LASSO系数
beta_hat2=coef(lasso_fit)
par(mfrow=c(1,2))
#作图
plot(lasso_fit,xvar="lambda",col=1:9,label=TRUE)
#从图中可以看出，随着调优参数值的增加，第五个变量(浅蓝色)Epith.c.size是第一个退出模型的变量,接着是第九个Mitoses，接着是第6个(黄色)Bare.nuclei，第7个变量(紫色)Bl.cromatin
#为调优参数选择一个合适的值，同样利用10倍交叉验证
#fit model,applying 10-fold cross validation
lasso_cv_fit=cv.glmnet(as.matrix(bre_train[,1:9]),y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family="binomial",type.measure="class")
##plot the cross-validation
plot(lasso_cv_fit)
install.packages("ProjectTemplate")
library(ProjectTemplate)
setwd("~/Desktop")
create.project("MA")
setwd("MA/reports")
library(tinytex)
tinytex::install_prebuilt(pkg="/Users/wangyimiao/Desktop/TinyTex.zip")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)
load.project()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
library(ProjectTemplate)
load.project()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))
###Project###
##Load mlbench package
library(mlbench)
##Load the data
data(BreastCancer)
dim(BreastCancer)
##print first few rows
head(BreastCancer)
#查看第二行第二列的数据类型
class(BreastCancer[2,2])
#将因子转化为定量变量,将class作为响应变量，将其作为一个因素储存
head(BreastCancer$Class)
breast=apply(BreastCancer[,2:10],2,as.numeric)
#良性作为1，恶性作为2 Benign as 1, malignant as 2
typeof(BreastCancer$Class)
head(as.integer(BreastCancer$Class))
#在做逻辑回归模型时，用0/1区分良性和恶性，创建新的列
bre_data=data.frame(ID=BreastCancer[,1],breast,Class=as.integer(BreastCancer$Class)-1)
##print the rows
head(bre_data)
#查看第二行第二列的数据类型,说明已经将因子转化成定量变量
class(bre_data[2,2])
##缺失数据的识别
is.na(bre_data)
#输出缺失值的个数
(n<-sum(is.na(bre_data)))
#提取缺失值所在的行
which(rowSums(is.na(bre_data))==TRUE)
#删除所有存在缺失值的行
bre_data1=na.omit(bre_data)
bre_data1
dim(bre_data1)
(n<-sum(is.na(bre_data1)))
##探索性数据分析
table(bre_data1$Class)
##可视化数据
pairs(bre_data1[,2:10],col=bre_data1[,11]+1)
#为了方便计算测试误差，将数据集分成训练集和测试集,按照8:2分
set.seed(1234)
sub=sample(1:nrow(bre_data1),round(nrow(bre_data1)*8/10))
#8/10的数据做训练
data_train=bre_data1[sub,]
bre_data1_train=as.data.frame(data_train[,2:10])
(n<-sum(is.na(bre_data1_train)))
y1_bre_train=data_train[,11]
mode(y1_bre_train)
bre_train=data.frame(bre_data1_train,Class=y1_bre_train)
bre_train
dim(bre_train)
#2/10的数据做测试
data_test=bre_data1[-sub,]
bre_data1_test=as.data.frame(data_test[,2:10])
y1_data_test=data_test[,11]
bre_test=data.frame(bre_data1_test,Class=y1_data_test)
dim(bre_test)
#将训练集数据拟合逻辑回归
lr_fit=glm(Class~.,data=bre_train,family="binomial")
summary(lr_fit)
#compute predicted probabilities
phat=predict(lr_fit,bre_train,type="response")
#compute fitted
yhat=ifelse(phat>0.5,1,0)
#calculate confusion matrix
(confusion=table(Observed=bre_train$Class,Predicted=yhat))
##test error
#fit logisitic regression model to training data:
phat_test=predict(lr_fit,bre_test,type="response")
yhat_test=ifelse(phat_test>0.5,1,0)
(confusion_test=table(Observed=bre_test$Class,Predicted=yhat_test))
#从混淆矩阵中可以看出在34+1=35次中正确预测了34次乳腺癌为恶性的概率,在100+2=102次预测乳腺癌为良性中，有100次预测正确
1-mean(bre_test$Class==yhat_test)
##BIC最佳子集的选择
library(leaps)
#将训练集数据拟合逻辑回归
lr_fit=glm(Class~cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Mitoses,data=bre_train,family="binomial")
#将训练集数据拟合逻辑回归
lr_fit=glm(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Mitoses,data=bre_train,family="binomial")
summary(lr_fit)
#compute predicted probabilities
phat=predict(lr_fit,bre_train,type="response")
#compute fitted
yhat=ifelse(phat>0.5,1,0)
#calculate confusion matrix
(confusion=table(Observed=bre_train$Class,Predicted=yhat))
##test error
#fit logisitic regression model to training data:
phat_test=predict(lr_fit,bre_test,type="response")
yhat_test=ifelse(phat_test>0.5,1,0)
(confusion_test=table(Observed=bre_test$Class,Predicted=yhat_test))
#从混淆矩阵中可以看出在34+1=35次中正确预测了34次乳腺癌为恶性的概率,在100+2=102次预测乳腺癌为良性中，有100次预测正确
1-mean(bre_test$Class==yhat_test)
##BIC最佳子集的选择
library(leaps)
library(bestglm)
Xy<-bre_train
(bss_train=bestglm(Xy=Xy,IC="BIC",CVArgs=list(Mehtod='HTF',K=10,REP=1),family=binomial))
summary(bss_train)
##简化模型,以显著的5个变量拟合逻辑模型
lr_fit2=glm(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli,data=bre_train,family="binomial")
summary(lr_fit2)
##training error
#compute predicted probabilities
phat=predict(lr_fit2,bre_train,type="response")
#compute fitted
yhat=ifelse(phat>0.5,1,0)
#calculate confusion matrix
(confusion=table(Observed=bre_train$Class,Predicted=yhat))
#从混淆矩阵中可以看出在10+194=204次中正确预测了194次乳腺癌为恶性的概率,在334+8=342次预测乳腺癌为良性中，有334次预测正确
#calculate the training error
1-mean(bre_train$Class==yhat)
#得到的训练误差为3.11%，说明模型预测的性能较好
##test error
#fit logisitic regression model to training data:
phat_test=predict(lr_fit2,bre_test,type="response")
yhat_test=ifelse(phat_test>0.5,1,0)
(confusion_test=table(Observed=bre_test$Class,Predicted=yhat_test))
#从混淆矩阵中可以看出在35+0=35次中正确预测了35次乳腺癌为恶性的概率,在100+2=102次预测乳腺癌为良性中，有100次预测正确
1-mean(bre_test$Class==yhat_test)
###回归正则化
##利用全部训练集做岭回归
library(glmnet)
#choose grid values for the tuning parameter
grid=10^seq(5,-3,length=100)
##fit a ridge regression model for each value of the tuning parameter
ridge_fit=glmnet(bre_train[,1:9],y1_bre_train,alpha=0,standardize=FALSE,lambda=grid,family = "binomial")
beta1_hat=coef(ridge_fit)
dim(beta1_hat)
par(mfrow=c(1,2))
plot(ridge_fit,xvar="lambda",col=1:9,label=TRUE)
#标签1到9表示对应的系数，可以看出，当时间对数约为5时，所有的回归系数本质上等于零
#因此需要为调优参数选择一个合适的值，这可以通过交叉验证来实现
ridge_cv_fit=cv.glmnet(as.matrix(bre_train[,1:9]),y1_bre_train,alpha=0,standardize=FALSE,lambda=grid,family = "binomial",type.measure = "class")
#display how the cross-validated error varies
plot(ridge_cv_fit)
#对于每一个值，平均MSE在k次折叠中随误差条绘制，提取对应于lambda的最小值
(lambda_min=ridge_cv_fit$lambda.min)
#The LASSO
#使用LASSO重新检查乳腺癌训练数据
#choose grid of values for the tuning parameter
grid=10^seq(5,-3,length=100)
#fit a LASSO regression for each value of the tuning parameter
lasso_fit=glmnet(bre_train[,1:9],y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family = "binomial")
#提取LASSO系数
beta_hat2=coef(lasso_fit)
par(mfrow=c(1,2))
#作图
plot(lasso_fit,xvar="lambda",col=1:9,label=TRUE)
#从图中可以看出，随着调优参数值的增加，第五个变量(浅蓝色)Epith.c.size是第一个退出模型的变量,接着是第九个Mitoses，接着是第6个(黄色)Bare.nuclei，第7个变量(紫色)Bl.cromatin
#为调优参数选择一个合适的值，同样利用10倍交叉验证
#fit model,applying 10-fold cross validation
lasso_cv_fit=cv.glmnet(as.matrix(bre_train[,1:9]),y1_bre_train,alpha=1,standardize=FALSE,lambda=grid,family="binomial",type.measure="class")
##plot the cross-validation
plot(lasso_cv_fit)
#extract the optimal value of the tuning parameter
(lambda_min2=lasso_cv_fit$lambda.min)
#调优参数最小的参数
(i2=which(lasso_cv_fit$lambda==lasso_cv_fit$lambda.min))
#extract corresponding mean MSE
lasso_cv_fit$cvm[i2]
#得到的平均MSE=0.03296
#通过LASSO计算回归系数
coef(lasso_fit,s=lambda_min2)
#在最优解上,选择除Epith.c.size，Cell.size 外所有解释变量
#重新拟合模型,使用lambda最小值
lasso_fit2= glmnet(bre_train[,1:9],bre_train[,10],alpha=1,standardize=FALSE,lambda=lambda_min2,family="binomial")
# Compute fitted values for test data:
phat_test_lasso = predict(lasso_fit2,as.matrix(bre_test[,1:9]), s=lambda_min2, type = "response")
yhat_test_lasso = ifelse(phat_test_lasso>0.5,1,0)
#Compute test error
(test_error_lasso = 1- mean((bre_test$Class ==yhat_test_lasso)))#2.18%
(confusion_test2 = table("observed"=bre_test$Class, "predicted"=yhat_test_lasso))
##判别分析##
##不剔除任何变量
library(nclSLR)
library(MASS)
linDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the LDA calssifier using the training data
lda_train1=lda(Class~.,data=bre_train)
summary(lda_train1)
#compute fitted the values for the validation data
lda_test1=predict(lda_train1,bre_test)
yhat_test1=lda_test1$class
#calculate test confusion matirx
(confusion_test3=table(Observed=bre_test$Class,Predicted=yhat_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_test1)#3.65%
##判别分析##
##不剔除任何变量
library(nclSLR)
library(MASS)
linDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the LDA calssifier using the training data
lda_train1=lda(Class~.,data=bre_train)
summary(lda_train1)
#compute fitted the values for the validation data
lda_test1=predict(lda_train1,bre_test)
yhat_test1=lda_test1$class
#calculate test confusion matirx
(confusion_test3=table(Observed=bre_test$Class,Predicted=yhat_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_test1)#3.65%
#用显著性强的6个变量做QDA
lda_train3=lda(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
lda_test3=predict(lda_train3,bre_test)
yhat_test3=lda_test3$class
#calculate test confusion matirx
(confusion_test8=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#4.38%
#剔除两个变量
##fit the LDA calssifier using the training data
lda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(lda_train2)
#compute fitted the values for the validation data
lda_test2=predict(lda_train2,bre_test)
yhat_test2=lda_test2$class
#calculate test confusion matirx
(confusion_test4=table(Observed=bre_test$Class,Predicted=yhat_test2))
#calculate the test error
1-mean(bre_test$Class==yhat_test2)#3.65%
##QDA,LASSO剔除2个变量
##fit the LDA calssifier using the training data
qda_train=qda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
summary(qda_train)
#compute fitted the values for the validation data
qda_test=predict(qda_train,bre_test)
yhat_test3=qda_test$class
#calculate test confusion matirx
(confusion_test5=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在35+0=35次中正确预测了35次乳腺癌为恶性的概率,在97+5=102次预测乳腺癌为良性中，有97次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#3.65%
##不剔除任何变量
quaDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the QDA calssifier using the training data
qda_train1=lda(Class~.,data=bre_train)
#compute fitted the values for the validation data
qda_test1=predict(qda_train1,bre_test)
yhat_qua_test1=qda_test1$class
#calculate test confusion matirx
(confusion_test6=table(Observed=bre_test$Class,Predicted=yhat_qua_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test1)#3.65%
#用显著性强的6个变量做QDA
qda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
#compute fitted the values for the validation data
qda_test2=predict(qda_train2,bre_test)
yhat_qua_test2=qda_test2$class
#calculate test confusion matirx
(confusion_test7=table(Observed=bre_test$Class,Predicted=yhat_qua_test2))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test2)#3.65%
#用显著性强的6个变量做LDA
lda_train3=lda(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli,data=bre_train)
#compute fitted the values for the validation data
lda_test3=predict(lda_train3,bre_test)
yhat_test3=lda_test3$class
#calculate test confusion matirx
(confusion_test8=table(Observed=bre_test$Class,Predicted=yhat_test3))
##从混淆矩阵中可以看出在30+5=35次中正确预测了30次乳腺癌为恶性的概率,在101+1=102次预测乳腺癌为良性中，有101次预测正确
#calculate the test error
1-mean(bre_test$Class==yhat_test3)#4.38%
##不剔除任何变量
quaDA(variables=bre_train[,1:9],group=bre_train[,10])
##fit the QDA calssifier using the training data
qda_train1=lda(Class~Cl.thickness+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli,data=bre_train)
#compute fitted the values for the validation data
qda_test1=predict(qda_train1,bre_test)
yhat_qua_test1=qda_test1$class
#calculate test confusion matirx
(confusion_test6=table(Observed=bre_test$Class,Predicted=yhat_qua_test1))
#calculate the test error
1-mean(bre_test$Class==yhat_qua_test1)#3.65%
#用显著性强的6个变量做QDA
qda_train2=lda(Class~Cl.thickness+Cell.shape+Marg.adhesion+Bare.nuclei+Bl.cromatin+Normal.nucleoli+Mitoses,data=bre_train)
